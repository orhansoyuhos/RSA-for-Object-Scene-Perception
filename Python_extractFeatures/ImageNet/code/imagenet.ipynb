{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1017b798-61dc-4b55-9fc9-5790fb6fbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265051f9-0507-4a65-a71d-64411c3e6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the architecture to use\n",
    "arch = 'resnet50'\n",
    "\n",
    "# resnet18, alexnet, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891b4312-6997-4b27-87e5-d89beb7295a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, use_pretrained=True):\n",
    "    model = None\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=use_pretrained)\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        model = models.alexnet(pretrained=use_pretrained)\n",
    "\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=use_pretrained)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a00ad6-1c5e-4449-8ba1-c319fd11c61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_model(arch)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f21af86-aefa-432e-99b4-bc5ae7352c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html\n",
    "\n",
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "##### REGISTER HOOK\n",
    "if arch == \"alexnet\":\n",
    "    model.features[0].register_forward_hook(get_features('conv1'))\n",
    "    model.features[3].register_forward_hook(get_features('conv2'))\n",
    "    model.features[6].register_forward_hook(get_features('conv3'))\n",
    "    model.features[8].register_forward_hook(get_features('conv4'))\n",
    "    model.features[10].register_forward_hook(get_features('conv5'))\n",
    "\n",
    "    model.classifier[1].register_forward_hook(get_features('linear1'))\n",
    "    model.classifier[4].register_forward_hook(get_features('linear2'))\n",
    "    model.classifier[6].register_forward_hook(get_features('linear3'))\n",
    "    \n",
    "elif arch == \"resnet50\":\n",
    "    model.conv1.register_forward_hook(get_features('conv1'))\n",
    "    model.layer1[2].conv3.register_forward_hook(get_features('conv2'))\n",
    "    model.layer2[2].conv3.register_forward_hook(get_features('conv3'))\n",
    "    model.layer3[2].conv3.register_forward_hook(get_features('conv4'))\n",
    "    model.layer4[2].conv3.register_forward_hook(get_features('conv5'))\n",
    "    model.fc.register_forward_hook(get_features('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d013e-c9b9-49d4-8a14-caddeec286bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ### Test the HYPOTHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31818353-54de-43bf-a9d8-3ff5fcf55250",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"C:/Users/ASUS/Desktop/Object vision group - Stefania Bracci/Workplaces/Workplace_11042022/Python_extractFeatures\"\n",
    "data_dir = f\"{main_dir}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97090bce-ab90-46b6-a083-c07b0839d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411a0b8c-5423-47ee-8844-a9d66e5c5c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders for RSA...\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'RSA': trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders for RSA...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "our_image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x).replace(\"\\\\\",\"/\"), data_transforms[x]) for x in ['RSA']}\n",
    "# Create training and validation dataloaders\n",
    "our_dataloaders_dict = {x: torch.utils.data.DataLoader(our_image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=2) for x in ['RSA']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba068a19-f341-48c3-8886-ac3d4b2d3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the names of images\n",
    "\n",
    "# for 'RSA' set\n",
    "nameTmp_dir_objects = f\"{main_dir}/data/RSA\\\\1-objects\\\\\"\n",
    "len_dir_objects = len(nameTmp_dir_objects)\n",
    "nameTmp_dir_both = f\"{main_dir}/data/RSA\\\\2-both\\\\\"\n",
    "len_dir_both = len(nameTmp_dir_both)\n",
    "nameTmp_dir_scenes = f\"{main_dir}/data/RSA\\\\3-scenes\\\\\"\n",
    "len_dir_scenes = len(nameTmp_dir_scenes)\n",
    "\n",
    "\n",
    "RSA_namesImg = []\n",
    "N = len(our_image_datasets['RSA'].imgs)\n",
    "for ii in range(0,N):\n",
    "    nameTmp = our_image_datasets['RSA'].imgs[ii][0]\n",
    "    if ii<64:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_objects:-4])\n",
    "    elif ii<128:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_both:-4])\n",
    "    elif ii<192:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_scenes:-4])\n",
    "\n",
    "    \n",
    "# RSA_namesImg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3653a5b3-b84f-42df-81a9-fe2961d0a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1-objects', '2-both', '3-scenes'], 192)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classNames = our_dataloaders_dict['RSA'].dataset.classes\n",
    "classNames, len(our_dataloaders_dict['RSA'].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b1b61-b236-4388-8305-d0c539725b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## # Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4da2693-5747-41c4-8d6d-6949846e5fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:41<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "##### FEATURE EXTRACTION LOOP\n",
    "\n",
    "typeData = 'RSA' # for reference\n",
    "\n",
    "if arch == \"alexnet\":\n",
    "    # placeholders\n",
    "    conv1 = []\n",
    "    conv2 = []\n",
    "    conv3 = []\n",
    "    conv4 = []\n",
    "    conv5 = []\n",
    "\n",
    "    linear1 = []\n",
    "    linear2 = []\n",
    "    linear3 = []\n",
    "\n",
    "    # placeholder for batch features\n",
    "    features = {}\n",
    "\n",
    "    for inputs, labels in tqdm(our_dataloaders_dict[typeData]):\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(inputs)\n",
    "\n",
    "        # add feats and preds to lists\n",
    "        conv1.append(features['conv1'].numpy())\n",
    "        conv2.append(features['conv2'].numpy())\n",
    "        conv3.append(features['conv3'].numpy())\n",
    "        conv4.append(features['conv4'].numpy())\n",
    "        conv5.append(features['conv5'].numpy())\n",
    "\n",
    "        linear1.append(features['linear1'].numpy())\n",
    "        linear2.append(features['linear2'].numpy())\n",
    "        linear3.append(features['linear3'].numpy())\n",
    "        \n",
    "elif arch == \"resnet50\":\n",
    "    # placeholders\n",
    "    conv1 = []\n",
    "    conv2 = []\n",
    "    conv3 = []\n",
    "    conv4 = []\n",
    "    conv5 = []\n",
    "\n",
    "    linear = []\n",
    "\n",
    "    # placeholder for batch features\n",
    "    features = {}\n",
    "\n",
    "    for inputs, labels in tqdm(our_dataloaders_dict[typeData]):\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(inputs)\n",
    "\n",
    "        # add feats and preds to lists\n",
    "        conv1.append(features['conv1'].numpy())\n",
    "        conv2.append(features['conv2'].numpy())\n",
    "        conv3.append(features['conv3'].numpy())\n",
    "        conv4.append(features['conv4'].numpy())\n",
    "        conv5.append(features['conv5'].numpy())\n",
    "\n",
    "        linear.append(features['linear'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8f1d11-7c6c-472b-af0e-e822a67f4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- conv1 shape: (192, 64, 112, 112)\n",
      "- conv2 shape: (192, 256, 56, 56)\n",
      "- conv3 shape: (192, 512, 28, 28)\n",
      "- conv4 shape: (192, 1024, 14, 14)\n",
      "- conv5 shape: (192, 2048, 7, 7)\n",
      "- linear shape: (192, 1000)\n"
     ]
    }
   ],
   "source": [
    "##### INSPECT FEATURES\n",
    "\n",
    "if arch == \"alexnet\":\n",
    "    conv1 = np.concatenate(conv1)\n",
    "    conv2 = np.concatenate(conv2)\n",
    "    conv3 = np.concatenate(conv3)\n",
    "    conv4 = np.concatenate(conv4)\n",
    "    conv5 = np.concatenate(conv5)\n",
    "\n",
    "    linear1 = np.concatenate(linear1)\n",
    "    linear2 = np.concatenate(linear2)\n",
    "    linear3 = np.concatenate(linear3)\n",
    "\n",
    "    print('- conv1 shape:', conv1.shape)\n",
    "    print('- conv2 shape:', conv2.shape)\n",
    "    print('- conv3 shape:', conv3.shape)\n",
    "    print('- conv4 shape:', conv4.shape)\n",
    "    print('- conv5 shape:', conv5.shape)\n",
    "\n",
    "    print('- linear1 shape:', linear1.shape)\n",
    "    print('- linear2 shape:', linear2.shape)\n",
    "    print('- linear3 shape:', linear3.shape)\n",
    "    \n",
    "elif arch == \"resnet50\":\n",
    "    conv1 = np.concatenate(conv1)\n",
    "    conv2 = np.concatenate(conv2)\n",
    "    conv3 = np.concatenate(conv3)\n",
    "    conv4 = np.concatenate(conv4)\n",
    "    conv5 = np.concatenate(conv5)\n",
    "\n",
    "    linear = np.concatenate(linear)\n",
    "\n",
    "    print('- conv1 shape:', conv1.shape)\n",
    "    print('- conv2 shape:', conv2.shape)\n",
    "    print('- conv3 shape:', conv3.shape)\n",
    "    print('- conv4 shape:', conv4.shape)\n",
    "    print('- conv5 shape:', conv5.shape)\n",
    "\n",
    "    print('- linear shape:', linear.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2ce591-b897-47e9-b067-0bcf12cbde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDic = dict\n",
    "\n",
    "if arch == \"alexnet\":\n",
    "    resultDic = {\"dataType\": typeData, \"RSA_namesImg\": RSA_namesImg,\n",
    "                 \"conv1\": conv1, \"conv2\": conv2, \"conv3\": conv3, \"conv4\": conv4, \"conv5\": conv5,\n",
    "                 \"linear1\": linear1, \"linear2\": linear2, \"linear3\": linear3}\n",
    "elif arch == \"resnet50\":\n",
    "    resultDic = {\"dataType\": typeData, \"RSA_namesImg\": RSA_namesImg,\n",
    "                 \"conv1\": conv1, \"conv2\": conv2, \"conv3\": conv3, \"conv4\": conv4, \"conv5\": conv5,\n",
    "                 \"linear\": linear}\n",
    "\n",
    "save_dir = f\"{main_dir}/resultDic/\"\n",
    "os.makedirs(save_dir, exist_ok = True)\n",
    "savemat(f'{save_dir}{typeData}_resultDic_imagenet_{arch}.mat', resultDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56735c1d-4dfc-47cb-be3f-fad753a04912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.6403172 , -2.5605586 , -2.270606  , -2.2329824 , -2.212966  ,\n",
       "       -2.239099  , -2.2469954 , -2.2478147 , -2.2265952 , -2.1808722 ,\n",
       "       -2.1468241 , -2.1523309 , -2.183265  , -2.181505  , -2.1638916 ,\n",
       "       -2.1591716 , -2.129959  , -2.103543  , -2.1054652 , -2.1094918 ,\n",
       "       -2.1050446 , -2.0997262 , -2.076794  , -2.0724282 , -2.0755517 ,\n",
       "       -2.0596561 , -2.037902  , -2.0504239 , -2.0461552 , -2.0390081 ,\n",
       "       -2.036217  , -2.0418673 , -2.024305  , -2.0164416 , -2.034613  ,\n",
       "       -2.0369735 , -2.0104628 , -1.9944062 , -1.9954331 , -1.9954331 ,\n",
       "       -1.9967449 , -1.9963818 , -1.9949574 , -1.9954038 , -1.9874294 ,\n",
       "       -1.9602716 , -1.9488008 , -1.9455204 , -1.9460413 , -1.9420956 ,\n",
       "       -1.9359642 , -1.9296342 , -1.9229785 , -1.9252954 , -1.9350379 ,\n",
       "       -1.9450889 , -1.9430118 , -1.9347172 , -1.9323473 , -1.9323473 ,\n",
       "       -1.9326305 , -1.9480798 , -1.9697824 , -1.9671736 , -1.9661672 ,\n",
       "       -1.9964082 , -1.9945092 , -1.997051  , -2.0059228 , -2.0483286 ,\n",
       "       -2.0732105 , -2.0545042 , -2.0560622 , -2.0651884 , -2.0606296 ,\n",
       "       -2.052335  , -2.049148  , -2.0362315 , -2.0437982 , -2.0694714 ,\n",
       "       -2.0812607 , -2.0930786 , -2.1063726 , -2.2218766 , -2.0496595 ,\n",
       "       -1.5656377 , -0.30111495,  1.222472  ,  2.3575273 ,  3.0422094 ,\n",
       "        3.5791996 ,  3.8995643 ,  3.9542243 ,  3.956413  ,  3.9556267 ,\n",
       "        3.9560244 ,  3.9560244 ,  3.9560244 ,  3.9590065 ,  4.0718527 ,\n",
       "        4.006838  ,  3.373193  ,  0.8534356 , -1.2252381 , -1.923664  ,\n",
       "       -2.0843177 , -2.064392  , -2.0908124 , -2.0952525 , -2.0801086 ,\n",
       "       -2.0882778 , -0.7696065 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1[55,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bc3f0-8315-4e8f-b983-69010104d7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
