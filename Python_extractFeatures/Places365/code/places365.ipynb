{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e7243a-856f-4da4-b2da-07278dd7115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/CSAILVision/places365\n",
    "\n",
    "# PlacesCNN for scene classification\n",
    "#\n",
    "# by Bolei Zhou\n",
    "# last modified by Bolei Zhou, Dec.27, 2017 with latest pytorch and torchvision (upgrade your torchvision please if there is trn.Resize error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d477f7-ee8e-4e77-926c-391f105a2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3e9a36-98b4-4185-ba70-6f07ca743fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the architecture to use\n",
    "arch = 'resnet50'\n",
    "\n",
    "# resnet18, alexnet, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c499f003-d1df-4e95-8fb5-3f9fc09c0e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=365, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-trained weights\n",
    "model_file = '%s_places365.pth.tar' % arch\n",
    "if not os.access(model_file, os.W_OK):\n",
    "    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "    os.system('wget ' + weight_url)\n",
    "    \n",
    "model = models.__dict__[arch](num_classes=365)\n",
    "checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd922d34-0d76-4d74-aa06-63519e1dc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html\n",
    "\n",
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "##### REGISTER HOOK\n",
    "if arch == \"alexnet\":\n",
    "    model.features[0].register_forward_hook(get_features('conv1'))\n",
    "    model.features[3].register_forward_hook(get_features('conv2'))\n",
    "    model.features[6].register_forward_hook(get_features('conv3'))\n",
    "    model.features[8].register_forward_hook(get_features('conv4'))\n",
    "    model.features[10].register_forward_hook(get_features('conv5'))\n",
    "\n",
    "    model.classifier[1].register_forward_hook(get_features('linear1'))\n",
    "    model.classifier[4].register_forward_hook(get_features('linear2'))\n",
    "    model.classifier[6].register_forward_hook(get_features('linear3'))\n",
    "    \n",
    "elif arch == \"resnet50\":\n",
    "    model.conv1.register_forward_hook(get_features('conv1'))\n",
    "    model.layer1[2].conv3.register_forward_hook(get_features('conv2'))\n",
    "    model.layer2[2].conv3.register_forward_hook(get_features('conv3'))\n",
    "    model.layer3[2].conv3.register_forward_hook(get_features('conv4'))\n",
    "    model.layer4[2].conv3.register_forward_hook(get_features('conv5'))\n",
    "    model.fc.register_forward_hook(get_features('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84294384-977f-4b0e-ac04-7342421a57e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ### Test the HYPOTHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d346e67-b7c0-47ce-b251-8dcf842486c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"C:/Users/ASUS/Desktop/Object vision group - Stefania Bracci/Workplaces/Workplace_11042022/Python_extractFeatures\"\n",
    "data_dir = f\"{main_dir}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f073f552-1789-46a8-94e7-05bbaa4ee334",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05047460-b5e3-4a52-8c3f-8a5c961c4961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders for RSA...\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'RSA': trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders for RSA...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "our_image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x).replace(\"\\\\\",\"/\"), data_transforms[x]) for x in ['RSA']}\n",
    "# Create training and validation dataloaders\n",
    "our_dataloaders_dict = {x: torch.utils.data.DataLoader(our_image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=2) for x in ['RSA']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d30fcc8-6572-40b9-8c7d-f531cc708b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the names of images\n",
    "\n",
    "# for 'RSA' set\n",
    "nameTmp_dir_objects = f\"{main_dir}/data/RSA\\\\1-objects\\\\\"\n",
    "len_dir_objects = len(nameTmp_dir_objects)\n",
    "nameTmp_dir_both = f\"{main_dir}/data/RSA\\\\2-both\\\\\"\n",
    "len_dir_both = len(nameTmp_dir_both)\n",
    "nameTmp_dir_scenes = f\"{main_dir}/data/RSA\\\\3-scenes\\\\\"\n",
    "len_dir_scenes = len(nameTmp_dir_scenes)\n",
    "\n",
    "\n",
    "RSA_namesImg = []\n",
    "N = len(our_image_datasets['RSA'].imgs)\n",
    "for ii in range(0,N):\n",
    "    nameTmp = our_image_datasets['RSA'].imgs[ii][0]\n",
    "    if ii<64:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_objects:-4])\n",
    "    elif ii<128:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_both:-4])\n",
    "    elif ii<192:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_scenes:-4])\n",
    "\n",
    "    \n",
    "# RSA_namesImg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20f6cf6-6e92-4d34-bb7f-03f39fac5e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1-objects', '2-both', '3-scenes'], 192)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classNames = our_dataloaders_dict['RSA'].dataset.classes\n",
    "classNames, len(our_dataloaders_dict['RSA'].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca2372-549b-4b69-af9f-1bd5d348473c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## # Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d4fea9a-6717-4a3a-be8c-174f05250b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:48<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "##### FEATURE EXTRACTION LOOP\n",
    "\n",
    "typeData = 'RSA' # for reference\n",
    "\n",
    "if arch == \"alexnet\":\n",
    "    # placeholders\n",
    "    conv1 = []\n",
    "    conv2 = []\n",
    "    conv3 = []\n",
    "    conv4 = []\n",
    "    conv5 = []\n",
    "\n",
    "    linear1 = []\n",
    "    linear2 = []\n",
    "    linear3 = []\n",
    "\n",
    "    # placeholder for batch features\n",
    "    features = {}\n",
    "\n",
    "    for inputs, labels in tqdm(our_dataloaders_dict[typeData]):\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(inputs)\n",
    "\n",
    "        # add feats and preds to lists\n",
    "        conv1.append(features['conv1'].numpy())\n",
    "        conv2.append(features['conv2'].numpy())\n",
    "        conv3.append(features['conv3'].numpy())\n",
    "        conv4.append(features['conv4'].numpy())\n",
    "        conv5.append(features['conv5'].numpy())\n",
    "\n",
    "        linear1.append(features['linear1'].numpy())\n",
    "        linear2.append(features['linear2'].numpy())\n",
    "        linear3.append(features['linear3'].numpy())\n",
    "        \n",
    "elif arch == \"resnet50\":\n",
    "    # placeholders\n",
    "    conv1 = []\n",
    "    conv2 = []\n",
    "    conv3 = []\n",
    "    conv4 = []\n",
    "    conv5 = []\n",
    "\n",
    "    linear = []\n",
    "\n",
    "    # placeholder for batch features\n",
    "    features = {}\n",
    "\n",
    "    for inputs, labels in tqdm(our_dataloaders_dict[typeData]):\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(inputs)\n",
    "\n",
    "        # add feats and preds to lists\n",
    "        conv1.append(features['conv1'].numpy())\n",
    "        conv2.append(features['conv2'].numpy())\n",
    "        conv3.append(features['conv3'].numpy())\n",
    "        conv4.append(features['conv4'].numpy())\n",
    "        conv5.append(features['conv5'].numpy())\n",
    "\n",
    "        linear.append(features['linear'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4967843d-e043-4ef1-8630-e71d00980da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- conv1 shape: (192, 64, 112, 112)\n",
      "- conv2 shape: (192, 256, 56, 56)\n",
      "- conv3 shape: (192, 512, 28, 28)\n",
      "- conv4 shape: (192, 1024, 14, 14)\n",
      "- conv5 shape: (192, 2048, 7, 7)\n",
      "- linear shape: (192, 365)\n"
     ]
    }
   ],
   "source": [
    "##### INSPECT FEATURES\n",
    "\n",
    "if arch == \"alexnet\":\n",
    "    conv1 = np.concatenate(conv1)\n",
    "    conv2 = np.concatenate(conv2)\n",
    "    conv3 = np.concatenate(conv3)\n",
    "    conv4 = np.concatenate(conv4)\n",
    "    conv5 = np.concatenate(conv5)\n",
    "\n",
    "    linear1 = np.concatenate(linear1)\n",
    "    linear2 = np.concatenate(linear2)\n",
    "    linear3 = np.concatenate(linear3)\n",
    "\n",
    "    print('- conv1 shape:', conv1.shape)\n",
    "    print('- conv2 shape:', conv2.shape)\n",
    "    print('- conv3 shape:', conv3.shape)\n",
    "    print('- conv4 shape:', conv4.shape)\n",
    "    print('- conv5 shape:', conv5.shape)\n",
    "\n",
    "    print('- linear1 shape:', linear1.shape)\n",
    "    print('- linear2 shape:', linear2.shape)\n",
    "    print('- linear3 shape:', linear3.shape)\n",
    "    \n",
    "elif arch == \"resnet50\":\n",
    "    conv1 = np.concatenate(conv1)\n",
    "    conv2 = np.concatenate(conv2)\n",
    "    conv3 = np.concatenate(conv3)\n",
    "    conv4 = np.concatenate(conv4)\n",
    "    conv5 = np.concatenate(conv5)\n",
    "\n",
    "    linear = np.concatenate(linear)\n",
    "\n",
    "    print('- conv1 shape:', conv1.shape)\n",
    "    print('- conv2 shape:', conv2.shape)\n",
    "    print('- conv3 shape:', conv3.shape)\n",
    "    print('- conv4 shape:', conv4.shape)\n",
    "    print('- conv5 shape:', conv5.shape)\n",
    "\n",
    "    print('- linear shape:', linear.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98128686-41ab-4235-9b0c-40f841922fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDic = dict\n",
    "\n",
    "if arch == \"alexnet\":\n",
    "    resultDic = {\"dataType\": typeData, \"RSA_namesImg\": RSA_namesImg,\n",
    "                 \"conv1\": conv1, \"conv2\": conv2, \"conv3\": conv3, \"conv4\": conv4, \"conv5\": conv5,\n",
    "                 \"linear1\": linear1, \"linear2\": linear2, \"linear3\": linear3}\n",
    "elif arch == \"resnet50\":\n",
    "    resultDic = {\"dataType\": typeData, \"RSA_namesImg\": RSA_namesImg,\n",
    "                 \"conv1\": conv1, \"conv2\": conv2, \"conv3\": conv3, \"conv4\": conv4, \"conv5\": conv5,\n",
    "                 \"linear\": linear}\n",
    "\n",
    "save_dir = f\"{main_dir}/resultDic/\"\n",
    "os.makedirs(save_dir, exist_ok = True)\n",
    "savemat(f'{save_dir}{typeData}_resultDic_places365_{arch}.mat', resultDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5368336b-256a-40f9-bf40-986038266674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.6540583e-01, -3.8996805e-02, -3.3369474e-02, -2.6265992e-02,\n",
       "       -6.5851219e-02, -1.7324556e-02, -1.3238167e-03, -2.9851226e-02,\n",
       "       -1.7607968e-02,  3.2558010e-03, -1.2532903e-03, -8.4962938e-03,\n",
       "       -2.3346378e-02, -3.0046238e-03, -1.5544428e-03, -1.1076488e-02,\n",
       "       -1.3652444e-02,  3.1263594e-02,  1.6003013e-02,  9.8361373e-03,\n",
       "        3.9325650e-03,  2.4643604e-02,  1.1155719e-02,  2.4904346e-02,\n",
       "        1.9322425e-02,  2.0799050e-02,  3.6371831e-02,  2.2126755e-02,\n",
       "        4.1242015e-02,  1.6053513e-02,  3.7642028e-02,  3.3496913e-02,\n",
       "        8.3136810e-03,  5.3672113e-02,  2.5868285e-02,  8.2028611e-03,\n",
       "        7.1367405e-02,  5.9274666e-02,  5.0669663e-02,  5.0669663e-02,\n",
       "        4.7892623e-02,  4.8243038e-02,  5.1322453e-02,  5.1778242e-02,\n",
       "        4.3978620e-02,  5.9695102e-02,  6.7099877e-02,  7.2271191e-02,\n",
       "        6.6337682e-02,  5.9261795e-02,  6.7152068e-02,  6.8242177e-02,\n",
       "        6.4751573e-02,  5.6441952e-02,  5.1977757e-02,  5.9909943e-02,\n",
       "        6.6499688e-02,  5.9539322e-02,  5.7973985e-02,  5.7973985e-02,\n",
       "        5.4155830e-02,  6.0771644e-02,  5.2995656e-02,  7.3581792e-02,\n",
       "        5.3282820e-02,  5.3727470e-02,  5.2639846e-02,  5.7059933e-02,\n",
       "        3.7284393e-02,  4.4552844e-02,  1.2775069e-02,  2.9519763e-02,\n",
       "        3.7526753e-02,  3.7035640e-02,  4.2357888e-02,  3.5397466e-02,\n",
       "        3.4740884e-02,  4.7507875e-02,  5.6910884e-02,  6.1727022e-03,\n",
       "       -3.8627454e-03,  3.1982832e-02,  5.4884594e-02, -2.1550763e-01,\n",
       "       -9.5631588e-01, -1.4482607e-01,  5.9206837e-01,  1.5361869e+00,\n",
       "        1.7107047e+00,  2.1716907e+00,  1.8703486e+00,  1.4257534e+00,\n",
       "        1.3298759e+00,  1.3257117e+00,  1.3292561e+00,  1.3303018e+00,\n",
       "        1.3303018e+00,  1.3303018e+00,  1.3168232e+00,  1.7575287e+00,\n",
       "        4.7228398e+00, -6.4033431e-01, -3.3423615e+00, -6.6316152e-01,\n",
       "        9.3516096e-02,  2.8644022e-02,  5.0587080e-02, -2.6171722e-03,\n",
       "        3.0132476e-02,  1.7427763e-03,  5.4439105e-02,  2.5879762e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1[55,0,0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
