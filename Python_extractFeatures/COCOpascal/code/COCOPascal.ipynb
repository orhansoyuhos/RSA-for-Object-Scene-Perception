{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1017b798-61dc-4b55-9fc9-5790fb6fbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265051f9-0507-4a65-a71d-64411c3e6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the architecture to use\n",
    "arch = 'fcn_resnet50'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891b4312-6997-4b27-87e5-d89beb7295a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, use_pretrained=True):\n",
    "    model = None\n",
    "\n",
    "    if model_name == \"fcn_resnet50\":\n",
    "        model = models.segmentation.fcn_resnet50(pretrained=use_pretrained)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a00ad6-1c5e-4449-8ba1-c319fd11c61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_model(arch)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57269cbf-26a2-441c-ad6f-16297069b589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f21af86-aefa-432e-99b4-bc5ae7352c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html\n",
    "\n",
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "##### REGISTER HOOK\n",
    "if arch == \"fcn_resnet50\":\n",
    "    model.backbone['conv1'].register_forward_hook(get_features('b_conv1'))\n",
    "    model.backbone.layer1[2].conv3.register_forward_hook(get_features('b_conv2'))\n",
    "    model.backbone.layer2[2].conv3.register_forward_hook(get_features('b_conv3'))\n",
    "    model.backbone.layer3[2].conv3.register_forward_hook(get_features('b_conv4'))\n",
    "    model.backbone.layer4[2].conv3.register_forward_hook(get_features('b_conv5'))\n",
    "    model.classifier[4].register_forward_hook(get_features('c_conv'))\n",
    "    model.aux_classifier[4].register_forward_hook(get_features('aux_conv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d013e-c9b9-49d4-8a14-caddeec286bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ### Test the HYPOTHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31818353-54de-43bf-a9d8-3ff5fcf55250",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"C:/Users/ASUS/Desktop/Object vision group - Stefania Bracci/Workplaces/Workplace_11042022/Python_extractFeatures\"\n",
    "data_dir = f\"{main_dir}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97090bce-ab90-46b6-a083-c07b0839d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411a0b8c-5423-47ee-8844-a9d66e5c5c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders for RSA...\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'RSA': trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders for RSA...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "our_image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x).replace(\"\\\\\",\"/\"), data_transforms[x]) for x in ['RSA']}\n",
    "# Create training and validation dataloaders\n",
    "our_dataloaders_dict = {x: torch.utils.data.DataLoader(our_image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=2) for x in ['RSA']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba068a19-f341-48c3-8886-ac3d4b2d3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the names of images\n",
    "\n",
    "# for 'RSA' set\n",
    "nameTmp_dir_objects = f\"{main_dir}/data/RSA\\\\1-objects\\\\\"\n",
    "len_dir_objects = len(nameTmp_dir_objects)\n",
    "nameTmp_dir_both = f\"{main_dir}/data/RSA\\\\2-both\\\\\"\n",
    "len_dir_both = len(nameTmp_dir_both)\n",
    "nameTmp_dir_scenes = f\"{main_dir}/data/RSA\\\\3-scenes\\\\\"\n",
    "len_dir_scenes = len(nameTmp_dir_scenes)\n",
    "\n",
    "\n",
    "RSA_namesImg = []\n",
    "N = len(our_image_datasets['RSA'].imgs)\n",
    "for ii in range(0,N):\n",
    "    nameTmp = our_image_datasets['RSA'].imgs[ii][0]\n",
    "    if ii<64:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_objects:-4])\n",
    "    elif ii<128:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_both:-4])\n",
    "    elif ii<192:\n",
    "        RSA_namesImg.append(nameTmp[len_dir_scenes:-4])\n",
    "\n",
    "    \n",
    "# RSA_namesImg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3653a5b3-b84f-42df-81a9-fe2961d0a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1-objects', '2-both', '3-scenes'], 192)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classNames = our_dataloaders_dict['RSA'].dataset.classes\n",
    "classNames, len(our_dataloaders_dict['RSA'].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b1b61-b236-4388-8305-d0c539725b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## # Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4da2693-5747-41c4-8d6d-6949846e5fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [02:45<00:00,  6.90s/it]\n"
     ]
    }
   ],
   "source": [
    "##### FEATURE EXTRACTION LOOP\n",
    "if arch == \"fcn_resnet50\":\n",
    "    typeData = 'RSA' # for reference\n",
    "\n",
    "    # placeholders\n",
    "    b_conv1 = []\n",
    "    b_conv2 = []\n",
    "    b_conv3 = []\n",
    "    b_conv4 = []\n",
    "    b_conv5 = []\n",
    "\n",
    "    c_conv = []\n",
    "    aux_conv = []\n",
    "\n",
    "    # placeholder for batch features\n",
    "    features = {}\n",
    "\n",
    "    for inputs, labels in tqdm(our_dataloaders_dict[typeData]):\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(inputs)\n",
    "\n",
    "        # add feats and preds to lists\n",
    "        b_conv1.append(features['b_conv1'].numpy())\n",
    "        b_conv2.append(features['b_conv2'].numpy())\n",
    "        b_conv3.append(features['b_conv3'].numpy())\n",
    "        b_conv4.append(features['b_conv4'].numpy())\n",
    "        b_conv5.append(features['b_conv5'].numpy())\n",
    "\n",
    "        c_conv.append(features['c_conv'].numpy())\n",
    "        aux_conv.append(features['aux_conv'].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8f1d11-7c6c-472b-af0e-e822a67f4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- b_conv1 shape: (192, 64, 112, 112)\n",
      "- b_conv2 shape: (192, 256, 56, 56)\n",
      "- b_conv3 shape: (192, 512, 28, 28)\n",
      "- b_conv4 shape: (192, 1024, 28, 28)\n",
      "- b_conv5 shape: (192, 2048, 28, 28)\n",
      "- c_conv shape: (192, 21, 28, 28)\n",
      "- aux_conv shape: (192, 21, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "##### INSPECT FEATURES\n",
    "\n",
    "b_conv1 = np.concatenate(b_conv1)\n",
    "b_conv2 = np.concatenate(b_conv2)\n",
    "b_conv3 = np.concatenate(b_conv3)\n",
    "b_conv4 = np.concatenate(b_conv4)\n",
    "b_conv5 = np.concatenate(b_conv5)\n",
    "\n",
    "c_conv = np.concatenate(c_conv)\n",
    "aux_conv = np.concatenate(aux_conv)\n",
    "\n",
    "print('- b_conv1 shape:', b_conv1.shape)\n",
    "print('- b_conv2 shape:', b_conv2.shape)\n",
    "print('- b_conv3 shape:', b_conv3.shape)\n",
    "print('- b_conv4 shape:', b_conv4.shape)\n",
    "print('- b_conv5 shape:', b_conv5.shape)\n",
    "\n",
    "print('- c_conv shape:', c_conv.shape)\n",
    "print('- aux_conv shape:', aux_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2ce591-b897-47e9-b067-0bcf12cbde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDic = dict\n",
    "\n",
    "if arch == \"fcn_resnet50\":\n",
    "    resultDic = {\"dataType\": typeData, \"RSA_namesImg\": RSA_namesImg,\n",
    "                 \"b_conv1\": b_conv1, \"b_conv2\": b_conv2, \"b_conv3\": b_conv3, \"b_conv4\": b_conv4, \"b_conv5\": b_conv5,\n",
    "                 \"c_conv\": c_conv, \"aux_conv\": aux_conv}\n",
    "\n",
    "save_dir = f\"{main_dir}/resultDic/\"\n",
    "os.makedirs(save_dir, exist_ok = True)\n",
    "savemat(f'{save_dir}{typeData}_resultDic_COCOpascal_{arch}.mat', resultDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56735c1d-4dfc-47cb-be3f-fad753a04912",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1[55,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bc3f0-8315-4e8f-b983-69010104d7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
